---
title: "Game Analytics: From Bootstrapping to Predictive Modeling"
author: "Hoang Son Lai"
date: "Nov 17, 2025"
format:
    html: 
        output-file: game_analytics.html
        css: "assignment.css"
        embed-resources: true
        code-fold: true
        toc: true
        toc-depth: 4
---

```{r}
#| echo: false
# Set up chunk for all slides
knitr::opts_chunk$set(
  fig.width = 6,
  fig.height = 4,
  fig.align = "center",
  out.width = "100%",
  code.line.numbers = FALSE,
  fig.retina = 4,
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  cache = FALSE,
  dev.args = list(pointsize = 11)
)
```

```{r}
#| echo: false
# Load libraries
library(tidyverse)
library(conflicted)
library(readr)
library(dplyr)
library(ggplot2)
library(janitor)
library(knitr)
library(scales)
library(naniar)
library(lubridate)
library(tidytext)
library(viridis)
library(plotly)
library(patchwork)
library(purrr)
library(gt)
library(DT)
library(kableExtra)
library(stringr)
library(tidyr)
library(forcats)
library(caret)
library(randomForest)
library(cluster)
library(factoextra)
library(corrplot)
library(ggpubr)
library(RColorBrewer)
library(broom)
library(colorspace)
library(GGally)
library(tibble)
library(highcharter)
library(htmltools)
library(jsonlite)

conflicts_prefer(dplyr::filter)
conflicts_prefer(dplyr::select)
conflicts_prefer(dplyr::slice)
conflicts_prefer(plotly::layout)

# Set random seed for reproducibility
set.seed(123)
```

# 1. Data Overview & Preprocessing

```{r}
# Load and clean the data
game_data <- read.csv("data/game_sessions.csv", stringsAsFactors = FALSE)

# Data cleaning and preprocessing
game_data_clean <- game_data %>%
  mutate(
    start_time = as.POSIXct(start_time, format = "%Y-%m-%dT%H:%M:%OSZ"),
    end_time = as.POSIXct(end_time, format = "%Y-%m-%dT%H:%M:%OSZ"),
    death_reason = as.factor(death_reason),
    # Handle missing end_time
    game_duration = ifelse(is.na(game_duration), 0, game_duration),
    # Create performance metrics
    score_per_second = ifelse(game_duration > 0, score / game_duration, 0),
    accuracy = ifelse(bullets_fired > 0, ufos_shot / bullets_fired, 0)
  ) %>%
  filter(!is.na(start_time))  
```

```{r}
# Display basic information
cat("Dataset Dimensions:", dim(game_data_clean), "\n")
cat("Date Range:", as.character(min(game_data_clean$start_time)), "to", 
    as.character(max(game_data_clean$start_time)), "\n")
```

```{r}
library(gt)
library(dplyr)

variable_description <- tibble(
  Variable = c(
    "id",
    "start_time",
    "end_time",
    "score",
    "coins_collected",
    "ufos_shot",
    "bullets_fired",
    "death_reason",
    "game_duration",
    "pipes_passed",
    "score_per_second",
    "accuracy"
  ),
  Description = c(
    "Unique session identifier",
    "Timestamp when the game session started",
    "Timestamp when the game session ended",
    "Final score achieved in the session",
    "Number of coins collected by the player",
    "Number of UFO enemies shot",
    "Total number of bullets fired",
    "Cause of death (collision type / hazard)",
    "Total session duration in seconds",
    "Number of pipes the player successfully passed",
    "Score normalized by session duration (score รท seconds)",
    "Shooting accuracy (ufos_shot รท bullets_fired)"
  ),
  Type = c(
    "Character",
    "Datetime",
    "Datetime",
    "Integer",
    "Integer",
    "Integer",
    "Integer",
    "Categorical",
    "Numeric",
    "Integer",
    "Numeric",
    "Numeric"
  )
)

variable_description %>%
  gt() %>%
  tab_header(
    title = md("**Variable Description - Plane Game Analytics**")
  ) %>%
  cols_width(
    Variable ~ px(160),
    Description ~ px(420),
    Type ~ px(120)
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  )

```

```{r}
# Summary statistics
game_data_clean %>%
  select(score, game_duration, coins_collected, ufos_shot, bullets_fired, pipes_passed, accuracy) %>%
  summary() %>%
  kable(caption = "Summary statistics")
```

# 2. Exploratory Data Analysis

In this section, I analyze the distribution of key metrics and investigate relationships between variables to understand player behavior before modeling.

## 2.1 Distribution of Key Metrics

```{r}
#| label: eda-distributions
#| warning: false
#| fig.width: 10
#| fig.height: 4

library(ggplot2)
library(gridExtra)

# Histogram of Scores
p1 <- ggplot(game_data_clean, aes(x = score)) +
  geom_histogram(binwidth = 5, fill = "#4e79a7", color = "white", alpha = 0.8) +
  labs(title = "Distribution of Player Scores", x = "Score", y = "Count") +
  theme_minimal()

# Histogram of Game Duration
p2 <- ggplot(game_data_clean, aes(x = game_duration)) +
  geom_histogram(binwidth = 5, fill = "#f28e2b", color = "white", alpha = 0.8) +
  labs(title = "Distribution of Game Duration", x = "Duration (seconds)", y = "Count") +
  theme_minimal()

grid.arrange(p1, p2, ncol = 2)
```

## 2.2 Death Reason Analysis

Understanding why players fail is crucial for adjusting game difficulty.

```{r}
#| label: eda-death-reason
#| fig.width: 8
#| fig.height: 5

# Bar chart for death reasons
game_data_clean %>%
  filter(!is.na(death_reason)) %>%
  count(death_reason, sort = TRUE) %>%
  mutate(death_reason = reorder(death_reason, n)) %>%
  ggplot(aes(x = death_reason, y = n, fill = death_reason)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  labs(title = "Common Causes of Death", x = "Death Reason", y = "Frequency") +
  theme_minimal()
```

## 2.3 Correlation Matrix

We check for correlations between numeric variables to identify potential predictors.

```{r}
#| label: eda-correlation
#| fig.width: 8
#| fig.height: 8

library(corrplot)

# Select numeric columns for correlation
num_vars <- game_data_clean %>%
  select(score, game_duration, coins_collected, ufos_shot, bullets_fired, pipes_passed)

cor_matrix <- cor(num_vars, use = "complete.obs")

corrplot(cor_matrix, method = "color", type = "upper", 
         addCoef.col = "black", tl.col = "black", diag = FALSE,
         title = "Feature Correlation Matrix", mar = c(0,0,1,0))
```

# 3. Bootstrapping Data for Machine Learning

Since the original dataset is small (~300 rows), we will bootstrap the training set to create a larger dataset (10,000+ samples) for robust model training. We reserve the last 50 records as a strict holdout test set.

```{r}
#| label: data-bootstrapping

set.seed(123)

# 1. Split real data into Train (first 250) and Test (last 50)
# Sorting by start_time ensures we respect temporal order
game_sorted <- game_data_clean %>% arrange(start_time)
train_base <- head(game_sorted, 250)
test_holdout <- tail(game_sorted, 50)

# 2. Bootstrap the training data to 10,000 samples
# Sampling with replacement allows us to simulate a larger dataset based on observed patterns
bootstrap_size <- 10000
train_bootstrapped <- train_base %>%
  slice_sample(n = bootstrap_size, replace = TRUE) %>%
  mutate(is_synthetic = TRUE) # Flag for tracking

# Combine for verification (optional) but we will train on 'train_bootstrapped'
cat("Original Train Size:", nrow(train_base), "\n")
cat("Bootstrapped Train Size:", nrow(train_bootstrapped), "\n")
cat("Holdout Test Size:", nrow(test_holdout), "\n")
```

# 4. Player Segmentation (Clustering)

We use K-Means clustering to identify distinct player personas based on their performance metrics.

```{r}
#| label: player-clustering
#| warning: false

library(cluster)
library(factoextra)

# Select features for clustering
cluster_features <- train_bootstrapped %>%
  select(score, coins_collected, pipes_passed, ufos_shot, bullets_fired, game_duration)

# Scale the data
scaled_features <- scale(cluster_features)

# Determine optimal clusters (Elbow method - simplified for report)
# Using k=3 for broad segmentation: Beginners, Average, Pros
set.seed(123)
kmeans_model <- kmeans(scaled_features, centers = 3, nstart = 25)

# Add cluster labels back to the data
train_bootstrapped$cluster <- as.factor(kmeans_model$cluster)

# Visualize Clusters
fviz_cluster(kmeans_model, data = scaled_features,
             geom = "point",
             ellipse.type = "convex", 
             ggtheme = theme_minimal(),
             main = "Player Segmentation (K-Means)")

# Summary of clusters
train_bootstrapped %>%
  group_by(cluster) %>%
  summarise(
    Avg_Score = mean(score),
    Avg_Duration = mean(game_duration),
    Avg_Coins = mean(coins_collected),
    Count = n()
  ) %>%
  gt() %>%
  tab_header(title = "Cluster Profiles")
```

# 5. Predictive Modeling

## 5.1 Score Forecasting (Regression)

We use a Random Forest model to predict the final score based on gameplay metrics.

```{r}
#| label: model-score-rf
#| message: false

library(randomForest)
library(caret)

# Define features
features <- c("coins_collected", "ufos_shot", "bullets_fired", "game_duration", "pipes_passed")

# Train Random Forest on Bootstrapped Data
rf_model_score <- randomForest(
  as.formula(paste("score ~", paste(features, collapse = "+"))),
  data = train_bootstrapped,
  ntree = 100,
  importance = TRUE
)

# Predict on Holdout Test Set
predictions_rf <- predict(rf_model_score, newdata = test_holdout)

# Evaluate Performance (RMSE & R-squared)
rmse_val <- RMSE(predictions_rf, test_holdout$score)
r2_val <- R2(predictions_rf, test_holdout$score)

cat("Random Forest Performance on Holdout Set:\n")
cat("RMSE:", round(rmse_val, 2), "\n")
cat("R-Squared:", round(r2_val, 4), "\n")

# Variable Importance Plot
varImpPlot(rf_model_score, main = "Feature Importance for Score Prediction")
```

## 5.2 Survival Analysis (Logistic Regression)

We predict whether a player will survive past a specific "expert" threshold (e.g., 30 seconds). This is a binary classification problem.

```{r}
#| label: model-survival-logistic

# Define 'Survival' as lasting longer than 30 seconds
threshold <- 30

train_bootstrapped <- train_bootstrapped %>%
  mutate(survived_expert = as.factor(ifelse(game_duration > threshold, 1, 0)))

test_holdout <- test_holdout %>%
  mutate(survived_expert = as.factor(ifelse(game_duration > threshold, 1, 0)))

# Train Logistic Regression
# We remove variables that directly calculate duration/score to prevent data leakage, focusing on behavioral counts
log_model <- glm(survived_expert ~ bullets_fired + ufos_shot + coins_collected, 
                 data = train_bootstrapped, 
                 family = "binomial")

# Predict probabilities on Test Set
probs_survival <- predict(log_model, newdata = test_holdout, type = "response")
preds_survival <- ifelse(probs_survival > 0.5, 1, 0)

# Confusion Matrix
conf_matrix <- confusionMatrix(as.factor(preds_survival), test_holdout$survived_expert)

cat("Logistic Regression Accuracy:", round(conf_matrix$overall['Accuracy'], 4), "\n")
print(conf_matrix$table)
```

# 6. Business Insights & Recommendations

Based on the analysis above, we derive the following actionable insights:

## 6.1. Difficulty Balancing:

Observation: The death_reason analysis highlights the most common obstacles (e.g., pipes vs. enemies). If 'pipe' collisions are disproportionately high early in the game, the initial difficulty curve may be too steep.

Recommendation: Adjust the gap size or spawn rate of the leading cause of death in the first 10 seconds of gameplay to improve retention.

## 6.2. Player Segmentation Strategy:

Observation: K-Means clustering identified distinct groups. (Refer to cluster table: e.g., High-duration/low-coin collectors vs. Aggressive shooters).

Recommendation: Introduce targeted rewards.

- For 'Survivors' (High duration, low action): Introduce time-based achievements.

- For 'Shooters' (High bullets/UFOs): Offer weapon skins or visual upgrades for combat milestones.

## 6.3. Predictive Engagement:

Observation: The Random Forest model shows that specific actions (like coins_collected or ufos_shot) are strong predictors of high scores.

Recommendation: Create a tutorial or "Daily Mission" focusing on these high-value actions to teach new players how to achieve higher scores effectively.

## 6.4. Monetization Opportunities:

Observation: Players who survive past the 30-second threshold (analyzed in the Logistic Regression) show higher engagement.

Recommendation: Trigger "Continue?" ads or special offers only after a player has demonstrated this "expert" survival trait, as they are more invested in the session than a player who dies instantly.
